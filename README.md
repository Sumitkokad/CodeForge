# CodeForge
online compiler Integrated with chatbot
ğŸ§  Ollama + Django: Local LLM Integration (Phi-3 Example)
This project demonstrates how to integrate a local LLM (like Phi-3) served by Ollama into a Django backend via HTTP API.

ğŸš€ Features

ğŸ”Œ Connects Django to locally running Ollama server

ğŸ§  Supports any Ollama-compatible LLM (e.g., phi3, llama3, mistral)

ğŸ”¨ Simple API to send prompts and receive responses

ğŸ“¦ Easily extendable to frontend (React, Vite, etc.)

ğŸ“¦ Requirements

Python 3.10+

Django 4.x+

Ollama (installed locally)

Any pulled LLM model (phi3 used here)

ğŸ’  Setup Instructions

1. ğŸ”„ Clone the Repository

git clone https://github.com/yourusername/ollama-django-llm.git
cd ollama-django-llm

2. ğŸ“¦ Create & Activate Virtual Environment

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

3. ğŸ“… Install Python Dependencies

pip install -r requirements.txt

4. ğŸš€ Run Django Server

python manage.py runserver

5. ğŸ§  Start Ollama Server (in a new terminal)

ollama serve

Then pull & run a model:

ollama pull phi3

ğŸ“¡ API Usage

â–¶ï¸ Endpoint

GET /chat/?prompt=Your+question+here

ğŸ“Ÿ Sample Request

curl "http://localhost:8000/chat/?prompt=What+is+machine+learning"

âœ… Sample Response

{
  "response": "Machine learning is a subfield of artificial intelligence..."
}

ğŸ§© Project Structure

ollama_django/
â”œâ”€â”€ ollama_api.py         # Handles API calls to Ollama
â”œâ”€â”€ views.py              # Django views for interaction
â”œâ”€â”€ urls.py               # Routes API endpoints
â”œâ”€â”€ templates/            # (Optional) HTML templates
â””â”€â”€ ...

ğŸ“„ Sample Code â€” ollama_api.py

import requests

def call_phi3(prompt_text):
    url = "http://localhost:11434/api/generate"
    headers = {"Content-Type": "application/json"}
    data = {
        "model": "phi3",
        "prompt": prompt_text,
        "stream": False
    }
    response = requests.post(url, json=data, headers=headers)
    return response.json().get("response", "") if response.status_code == 200 else "Error: " + response.text

âœ¨ Future Plans

âœ… Add frontend (React + Vite)

ğŸ”„ Real-time streaming response (WebSockets)

ğŸ” Add auth & usage logging

ğŸ’ª Unit tests for API

ğŸ‘¨â€ğŸ’» Author

Sumit Ravindra KokadğŸ§  Final Year CSE | AI/ML EnthusiastğŸ“ Pune, IndiağŸ“§ sumitkokad@example.com

ğŸ“œ License

This project is licensed under the MIT License.

ğŸŒ Useful Links

Ollama Official Docs

Phi-3 Model

Django Docs

